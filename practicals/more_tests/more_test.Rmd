---
title: "The Chi-squared distribution and related tests"
author: "Denis Puthier"
date: '`r Sys.Date()`'
output:
  html_document:
    fig_caption: yes
    highlight: zenburn
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    fig_caption: yes
    highlight: zenburn
    toc: no
    toc_depth: 3
  word_document: default
css: course.css
---


<script type="">
    $(function() {
        $(".hideshow").click(function() {
                $(this).parent().find(".exo_code").toggle();
        });
            
    })
</script>

<style>
.exo_code {
  display:none;
}

pre  {
  background-color: #2C3539!important;
  color: white;
} 

pre.text {
  background-color: #2C3539 !important;
}

hr {
  color: grey !important;
}


hr {
  color: grey !important;
}
</style>



# The 	$\chi^2$ distribution

## Definition

**from wikipedia**: In probability theory and statistics, the chi-squared distribution (also chi-square or $\chi^2$-distribution) with k degrees of freedom is the distribution of a sum of the squares of k independent standard normal random variables.

In other words, given  $x_1, x_2, ... , x_i$, $k$ independent variables drawn from a normal distribution  with mean 0 and standard deviation1, then the sum of their squares:

$$Q\ = \sum_{i=1}^k x_i^2$$

is distributed according to the chi-squared distribution with $k$ degrees of freedom. It is generally denoted as 
$$Q\ \sim\ \chi^2(k)\ \ \text{or}\ \ Q\ \sim\ \chi^2_k .$$

## Probability density function of $\chi^2$ distribution 

The probability density function (pdf) of the chi-square distribution is:

$$f(x;\,k) =
\begin{cases}
  \dfrac{x^{\frac k 2 -1} e^{-\frac x 2}}{2^{\frac k 2} \Gamma\left(\frac k 2 \right)},  & x > 0; \\ 0, & \text{otherwise}.
\end{cases}$$


<div class="exo">
- Check, using a diagram and using standard R functions/operators that, for $k_val=5$ the mathematical formula fits with the values returns by *dchisq()* function.
</div>
<div class="hideshow"> << Hide | Show >> </div>
<div class="exo_code">
```{r}
k_val <- 5
x <- 0:30
denom = (2^(k_val/2)*gamma(k_val/2)) 
num = x^(k_val/2-1)*exp(-x/2)

plot(0:30, num/denom, 
     type="l",
     col="blue",
     panel.first = grid(),
     xlab="x",
     ylab="f(x;k)")
points(0:30,
       dchisq(0:30, df=k_val),
       col="red",
       lw=2,
       pch=16)
```
</div>


## Testing the model


In the exercice below will compare the $\chi^2$ distribution model to a distribution obtained by randomly computing values for $Q$ with a fixed degree of freedom. 

**NB**: Regarding R code, we will use "_" characters for naming variables instead of classical '.'. This refers to the official [Hadley style of coding](http://stat405.had.co.nz/r-style.html). This is more Pythonic !!



<div class="exo">
- create a variable $k\_val$ that will be set to 5.
- Using the *replicate()* function and the *rnorm()* function, create 100000 samples of size $k\_val$ taken from a normal distribution with population mean 0 and standard deviation 1.
- Using *colSums()*, compute, for each sample, the sum of the squares.
- Draw the distribution of the obtained dataset.
    - Using the *hist()* function.
    - Using the *density()* and *plot()* function.
- Using the *dchisq()* function, check that the obtained distribution is well modeled by the $\chi^2$ distribution.
- Compute the $\chi^2$ distribution using $k\_val$ ranging from 5 to 50 with step by 5. 
- Conclude.
</div>
<div class="hideshow"> << Hide | Show >> </div>
<div class="exo_code">
```{r}
#-----------------------------------------------------------------------
# Using the replicate() function and the rnorm() function, create 100000 
# samples of size k_val taken from a 
# normal distribution with population mean 0 and standard deviation 1
#-----------------------------------------------------------------------
n <- 100000
x_val <- replicate(n, rnorm(5, mean = 0, sd = 1))

#-----------------------------------------------------------------------
# Using *colSums()*, compute, for each sample, the sum of the squares.
#-----------------------------------------------------------------------
x_srqt_sum <- colSums(x_val^2)
par(mfrow=c(1,2))

#-----------------------------------------------------------------------
# Draw the distribution of the obtained dataset.
#-----------------------------------------------------------------------

hist(x_srqt_sum, 
     col="blue", 
     border = "white", 
     breaks = 100)
plot(density(x_srqt_sum), 
     lwd=2, 
     col="blue", 
     panel.first=grid(),
     xlab="x")

#-----------------------------------------------------------------------
# Using the *dchisq* function, check that the obtained distribution is 
# well modeled by the $\chi^2$ distribution.
#-----------------------------------------------------------------------
par(mfrow=c(1,1))
plot(density(x_srqt_sum), 
     lwd=2, 
     col="blue", 
     panel.first=grid(),
     xlab="x")
points(0:30,
       dchisq(0:30, df=k_val),
       col="red",
       lw=2,
       pch=16)

```

</div>



## Computing the $\chi^2$ distribution for various degree of freedom

TODO: intro

<div class="exo">
- Compute the $\chi^2$ distribution for various degree of freedom (1,5,15...50).
</div>
<div class="hideshow"> << Hide | Show >> </div>
<div class="exo_code">
```{r}

## Create a color palette
if(!require(RColorBrewer)) install.packages('RColorBrewer')
color_pal <- brewer.pal(11, name = "Paired")


## Compute and draw density diagram of Chi-squared Distribution
# The values taken by k will be successively 1,5,15...50
k_val <- c(1, seq(5, 50, by=5))

# Draw a Chi-squared Distribution for k = 1
xlim <- c(0,100)
i = 1
plot(seq(xlim[1], xlim[2], length.out = 100), 
     dchisq(k_val[i], x=seq(xlim[1], xlim[2], length.out = 100)), 
     type="l", col= color_pal[i], 
     panel.first = grid(),
     lwd=2,
     xlab="x",
     ylab="f(x;k)"
     )

for(i in 2:length(k_val)){
  points(seq(xlim[1], xlim[2], length.out = 100), 
         dchisq(k_val[i], x=seq(xlim[1], xlim[2], length.out = 100)), 
         type="l", 
         col= color_pal[i],
         lwd=2)
}

legend("topright", 
       legend=paste("k=", k_val, sep=""), 
       fill=color_pal)
```
</div>


# Chi-squared test

In statistics, a $\chi^2$ test, is a statistical test in which the sampling distribution of the test statistic follows a $\chi^2$ distribution under the null hypothesis. The $\chi^2$ statistics is used in several statistical tests. However, without other qualification, 'chi-squared test' is often used as short for Pearson's chi-squared test. The chi-squared test is used to determine whether there is a significant difference between the expected frequencies and the observed frequencies in one or more categories. 


## Pearson's chi-squared test

Suppose that n observations in a random sample from a population are classified into k mutually exclusive classes with respective observed numbers $x_i$ (for $i=1,2...k$),and a null hypothesis gives the probability $p_i$ that an observation falls into the ith class. So we have the expected numbers $m_i = np_i$ for all $i$, where:

$$\sum^k_{i=1}{p_i} = 1$$
$$\sum^k_{i=1}{m_i} =n\sum^k_{i=1}{p_i} = \sum_{i=1}^{k}x_i$$

Pearson proposed that, under the circumstance of the null hypothesis being correct, the score below follows $\chi^2$ distribution with $k-1$ degrees of freedom.


$$X^2=\sum^k_{i=1}{\frac{(x_i-m_i)^2}{m_i}}$$

This score is frequently viewed as:

$$X^2=\sum^k_{i=1}{\frac{(observed_i-expected_i)^2}{expected_i}}$$


### Using chi-squarred to test for goodness of fit


The Pearson's chi-squared test is frequently used to test whether a random variable $Y$ has a distribution that is compatible (*i.e* can be well modeled) with a known probability distribution (*e.g* normal, geometric, binomial...). It is thus a measure of, the goodness of fit, that is, how well the  model fits the variable $Y$. When testing for goodness of fit using a $chi^2$ test, the null hypothesis is thus "$Y$ follows a distribution P".


#### Example: testing for a Poisson distribution.


Let's consider a random variable $Y$ with null or positive discrete values. A sample of 100 values taken from$Y$ is provided below.


```{r}
y <- c(30, 43, 17, 8, 2)
names(y) <- c("0", "1", "2", "3", "4")
```
<div class="exo">
- Base on the provided sample, compute the expected mean ($\mu$) of the modeled Poisson distribution ($\mu=\sum_{i}^nx_ip_i$).
- What is the expected the number of events associated to value $0,1...4$ under a Poisson model with $\lambda=\mu$. Use de *dpois()* function. 
- Compute the $\chi^2$ statistics.
- Compute the p-value for the associated $\chi^2$ statistics.
- 
</div>
<div class="hideshow"> << Hide | Show >> </div>
<div class="exo_code">
```{r}
## Compute the expected mean of the modeled Poisson distribution
mu <- sum(0:4*y/100)

## What is the expected the number of events associated to value $0,1...4$ under a Poisson model with lambda=mu
expected <- dpois(0:4, lambda = mu) * 100

## Compute the chi-squarred statistics.
chi_stat <- sum((y-expected)^2/expected)



```
</div>

